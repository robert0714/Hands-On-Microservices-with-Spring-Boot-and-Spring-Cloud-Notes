<!-- MarkdownTOC -->
- [Ensuring that a service mesh is resilient](#ensuring-that-a-service-mesh-is-resilient)
	- [Testing resilience by injecting faults](#testing-resilience-by-injecting-faults)
	- [Testing resilience by injecting delays](#testing-resilience-by-injecting-delays)
<!-- /MarkdownTOC -->

# Ensuring that a service mesh is resilient

In this section, we will learn how to use Istio to ensure that a service mesh is resilient; that is, it can handle temporary faults in a service mesh. Istio comes with mechanisms similar to what the Spring Framework offers in terms of timeouts, retries, and a type of circuit breaker called ***outlier detection*** to handle temporary faults. When it comes to deciding whether language-native mechanisms should be used to handle temporary faults, or whether this should be delegated to a service mesh such as Istio, I tend to favor using language-native mechanisms, as in the examples in Chapter 13, Improving Resilience Using Resilience4J. In many cases, it is important to keep the logic for handling errors, for example, handling fallback alternatives for a circuit breaker, together with other business logic for a microservice.

There are cases when the corresponding mechanisms in Istio could be of great help. For example, if a microservice is deployed and it is determined that it can't handle temporary faults that occur in production from time to time, then it can be very convenient to add a timeout or a retry mechanism using Istio instead of waiting for a new release of the microservice with corresponding error handling features put in place.

Another capability in the area of resilience that comes with Istio is the capability to inject faults and delays into an existing service mesh. Why would anyone want to do that?

Injecting faults and delays in a controlled way is very useful for verifying that the resilient capabilities in the microservices work as expected! We will try them out in this section, verifying that the retry, timeout, and circuit breaker in the product-composite microservice work as expected.
 Calls to RabbitMQ, MySQL, and MongoDB are not handled by Istio proxies, and therefore require manual configuration to be protected using TLS.
  
- In Chapter 13, Improving Resilience Using Resilience4j (refer to the Adding programmable delays and random errors section), we added support for injecting faults and delays in the microservices source code. That source code can preferably be replaced by using Istio's capabilities for injecting faults and delays at runtime, as demonstrated in the following.

We will begin by injecting faults to see whether the retry mechanisms in the product- composite microservice work as expected. After that, we will delay the responses from the product service and verify that the circuit breaker handles the delay as expected.

## Testing resilience by injecting faults

Let's make the product service throw random errors and verify that the microservice landscape handles this correctly. We expect the retry mechanism in the product- composite microservice to kick in and retry the request until it succeeds or its limit of max numbers of retries is reached. This will ensure that a shortlived fault does not affect the end user more than the delay introduced by the retry attempts. Refer to the Adding a retry mechanism section in Chapter 13, Improving Resilience Using Resilience4j, for a recap on the retry mechanism in the product-composite microservice.

Faults can be injected using ***kubernetes/resilience-tests/product-virtual-service-with-faults.yml***. This appears as follows:
```bash
   apiVersion: networking.istio.io/v1alpha3
   kind: VirtualService
   metadata:
     name: product-vs
   spec:
     hosts:
       - product
     http:
     - route:
       - destination:
           host: product
       fault:
         abort:
           httpStatus: 500
           percent: 20
```
The definition says that 20% of the requests sent to the product service shall be aborted with the HTTP status code 500 (Internal Server Error).

Perform the following steps to test this:
1. Ensure that the load tests using ***siege***, as started in the Observing the ***service*** mesh section, are running.

2. Apply fault injection with the following command:
```
   kubectl apply -f kubernetes/resilience-tests/product-virtual-service-with-faults.yml
```

3. Monitor the output from the ***siege*** load tests tool. 
```
ACCESS_TOKEN=$(curl -k https://writer:secret@minikube.me/oauth/token -d    grant_type=password -d username=magnus -d password=password -s | jq  .access_token -r)
   
siege https://minikube.me/product-composite/2 -H "Authorization: Bearer    $ACCESS_TOKEN" -c1 -d1
```
Expect output similar to the following:
```
```
From the sample output, we can see that all requests are still successful, in other words, status 200 (OK) is returned; however, some of them (20%) take an extra second to complete. This indicates that the retry mechanism in the ***product-composite*** microservice has kicked in and has retried a failed request to the product service.

4. Kiali will also indicate that something is wrong with requests sent to the product service, as follows:
    1. Go to the call graph in Kiali's web UI that we used earlier to observe the traffic in our namespace, ***hands-on***.
    2. Click on the ***Display*** menu button and select ***Service Nodes***.
    3. Click on the menu button to the left of the ***Display*** button, named ***No edge labels***, and select the ***Response time*** option.
    4. The graph will show something like the following:

The arrow to the Service Node product will be shown in red to indicate that failed requests are detected. If we click on the arrow, we can see fault statistics to the right.

In the preceding sample screenshot, an error rate of 19.4% is reported, which corresponds well with the 20% we asked for. Note that the arrow from the Istio Gateway to the ***product-composite*** service is still green. This means that the retry mechanism in the ***product-composite*** service protects the end user; in other words, the faults do not propagate to the end user.

Conclude the removal of the fault injection with the following command:
```
 kubectl delete -f kubernetes/resilience-tests/product-virtual-service-with-faults.yml
``` 

Let's now move on to the next section, where we will inject delays to trigger the circuit breaker.

## Testing resilience by injecting delays

From Chapter 13, Improving Resilience Using Resilience4j (refer to the Introducing the circuit breaker section), we know that a circuit breaker can be used to prevent problems due to the slow response of services, or the fact that the services do not respond at all.

Let's verify that the circuit breaker in the product-composite service works as expected by injecting a delay into the product service using Istio. A delay can be injected using a virtual service.

Refer to ***kubernetes/resilience-tests/product-virtual-service-with-delay.yml***. Its code appears as follows:
```
   apiVersion: networking.istio.io/v1alpha3
   kind: VirtualService
   metadata:
     name: product-vs
   spec:
     hosts:
       - product
     http:
     - route:
       - destination:
           host: product
       fault:
         delay:
           fixedDelay: 3s
           percent: 100
```
The preceding definition says that all requests sent to the product service shall be delayed by 3 seconds.

Requests sent to the product service from the ***product-composite*** service are configured to timeout after 2 seconds. The circuit breaker is configured to open its circuit if 3 consecutive requests fail. When the circuit is open, it will fast-fail; in other words, it will immediately throw an exception, not attempting to call the underlying service. The business logic in the product-composite microservice will catch this exception and apply fallback logic. For a recap, see Chapter 13, Improving Resilience Using Resilience4j (refer to the Adding a circuit breaker section).
 
Perform the following steps to test the circuit breaker by injecting a delay:
1. Stop the load test run by means of the siege command by pressing Ctrl + C in the terminal window where siege is running.

2. Create a temporary delay in the product service with the following command:
```
   kubectl apply -f kubernetes/resilience-tests/product-virtual-service-with-delay.yml
```
3. Acquire an access token as follows:
```
ACCESS_TOKEN=$(curl -k https://writer:secret@minikube.me/oauth/token -d grant_type=password -d username=magnus -d password=password -s | jq .access_token -r)
```

4. Send six requests in a row. Expect the circuit to open up after the first three failed calls, that the circuit breaker applies fast-fail logic for the three last calls, and that a fallback response is returned, as follows:
```
   for i in {1..6}; do time curl -k https://minikube.me/product-composite/2 -H "Authorization: Bearer $ACCESS_TOKEN"; done
```

The responses from the first 3 calls are expected to be a timeout-related error message, and a response time of 2 seconds, in other words, the timeout time. Expect responses for the first 3 calls along the lines of the following:
```bash
{...."message":"Did not observe any item or terminal signal within 2000ms in 'onErrorResume' (and no fallback has been configured)","requestId":"aa056924-450"}curl -k https://minikube.me/product-composite/2 -H   0.02s user 0.01s system 1% cpu 2.056 total
....
```
The responses from the last 3 calls are expected to be a response from the fallback logic with a short response time. Expect responses for the last 3 calls as follows:
```bash
{"productId":2,"name":"Fallback product2",.....curl -k https://minikube.me/product-composite/2 -H   0.02s user 0.01s system 27% cpu 0.078 total

```

1. Simulate the fact that the delay problem is fixed by removing the temporary delay with the following command:
```
kubectl delete -f kubernetes/resilience-tests/product-virtual-service-with-delay.yml
```

2. Verify that correct answers are returned again and without any delay by sending a new request using the preceding command.

  - If you want to check the state of the circuit breaker, you can do it with the following command:
    ```
    curl product-composite.hands- on.svc.cluster.local:4004/actuator/health -s | jq -r .details.productCircuitBreaker.details.state
    ```
    It should report CLOSED, OPEN, or HALF_OPEN, depending on its state.

This proves that the circuit breaker reacts as expected when we inject a delay using Istio. This concludes testing features in Istio that can be used to verify that the microservice landscape is resilient. The final feature we will explore in Istio is its support for traffic management; we will establish how it can be used to enable deployments with zero downtime.
