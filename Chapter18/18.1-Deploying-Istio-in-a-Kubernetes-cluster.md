# Deploying Istio in a Kubernetes cluster
## Setting up access to Istio services
### Minikube
[reference](https://argoproj.github.io/argo-rollouts/getting-started/setup/)

1.Istio needs 8192MB of memory,4 CPUs .Start minikube with 16384 MB of memory and 4 CPUs.
```
minikube -p lab  start --memory=8192mb --cpus=4
```
- [Adding files](https://minikube.sigs.k8s.io/docs/handbook/filesync/)   
    Place files to be synced in $MINIKUBE_HOME/files   
    For example, running the following will result in the deployment of a custom /etc/resolv.conf:
    ```
    mkdir -p ~/.minikube/files/etc
    echo search cluster.local > ~/.minikube/files/etc/resolv.conf
    echo nameserver 10.96.0.10 > ~/.minikube/files/etc/resolv.conf
    ```   

2. Install istio by yaml
    - creating istio-system namepsace 
    ```bash
    $ kubectl create namespace istio-system
    ```
    - 賦予istio-system namespace的預設服務帳號擁有cluster-admin權限。
    ```bash
    $ kubectl create clusterrolebinding   istio-system-cluster-rolebinding  --clusterrole=cluster-admin  --serviceaccount=istio-system:default
    ```

    - Install Istio-specific custom resource definitions (CRDs) in Kubernetes:
    ```bash
    $ ISTIO_VERSION=1.5.10
    
    $env:Path += "; $HOME\istio-$ISTIO_VERSION\bin" # or  $env:Path += ";$PWD\bin"    
    $ export PATH="$PWD/istio-${ISTIO_VERSION}/bin:$PATH"
    
    $ cd istio-$ISTIO_VERSION
    $ for i in install/kubernetes/helm/istio-init/files/crd*yaml; do kubectl apply -f $i; done
    ```
    -  Install Istio demo configurations in Kubernetes as follows:
    ```bash
    $ kubectl apply -f install/kubernetes/istio-demo.yaml
    ```
    -  Wait for the Istio deployments to become available:
    ```
    kubectl -n istio-system wait --timeout=600s --for=condition=available deployment --all
    ```
    The command will report deployment resources in Istio as available, one after another. Expect 12 messages such as ***deployment.extensions/NNN condition met*** before the command ends. It can take a couple of minutes (or more) depending on your hardware and internet connectivity.
    -  Update Kiali's config map with URLs to Jaeger and Grafana with the following commands:   
       ( location: Chapter18/kubernetes/istio/setup/kiali-configmap.yml )
    ```bash
        kubectl -n istio-system apply -f kubernetes/istio/setup/kiali-configmap.yml && \
        kubectl -n istio-system delete pod -l app=kiali && \
        kubectl -n istio-system wait --timeout=60s --for=condition=ready pod -l app=kiali
    ``` 
    The config map, ***kubernetes/istio/setup/kiali-configmap.yml***, contains URLs to Jaeger and Grafana that utilize the DNS names set up by the minikube tunnel
command used in the next section.
    
    Istio is now deployed in Kubernetes, but before we move on and create the service mesh,we need to learn a bit about how to access Istio services in a Minikube environment.
    
or by minikube addons
```
minikube -p lab  addons enable istio-provisioner
minikube -p lab  addons enable istio
```
or  by [ istioctl](https://istio.io/latest/docs/setup/install/istioctl/)

```
$ istioctl install
```
or  by [ github releases](https://github.com/istio/istio/releases)
osx or linux 
```
$ curl -L https://git.io/getLatestIstio | ISTIO_VERSION=1.9.2 sh -
```
refer [this](https://istio.io/latest/docs/setup/getting-started/)   
```
$ cd istio-1.9.2
$ export PATH=$PWD/bin:$PATH
$ istioctl install --set profile=demo -y
✔ Istio core installed
✔ Istiod installed
✔ Egress gateways installed
✔ Ingress gateways installed
✔ Installation complete

$ kubectl label namespace default istio-injection=enabled
```

- Deploy the sample application
  1. Deploy the [Bookinfo sample application](https://istio.io/latest/docs/examples/bookinfo/):
    ```
    $ kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml
      service/details created
      serviceaccount/bookinfo-details created
      deployment.apps/details-v1 created
      service/ratings created
      serviceaccount/bookinfo-ratings created
      deployment.apps/ratings-v1 created
      service/reviews created
      serviceaccount/bookinfo-reviews created
      deployment.apps/reviews-v1 created
      deployment.apps/reviews-v2 created
      deployment.apps/reviews-v3 created
      service/productpage created
      serviceaccount/bookinfo-productpage created
      deployment.apps/productpage-v1 created
    ```
  2. The application will start. As each pod becomes ready, the Istio sidecar will be deployed along with it.
    ```
    $ kubectl get services
      NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
      details       ClusterIP   10.0.0.212      <none>        9080/TCP   29s
      kubernetes    ClusterIP   10.0.0.1        <none>        443/TCP    25m
      productpage   ClusterIP   10.0.0.57       <none>        9080/TCP   28s
      ratings       ClusterIP   10.0.0.33       <none>        9080/TCP   29s
      reviews       ClusterIP   10.0.0.28       <none>        9080/TCP   29s
    ```
    and
    ```
    $ kubectl get pods
      NAME                              READY   STATUS    RESTARTS   AGE
      details-v1-558b8b4b76-2llld       2/2     Running   0          2m41s
      productpage-v1-6987489c74-lpkgl   2/2     Running   0          2m40s
      ratings-v1-7dc98c7588-vzftc       2/2     Running   0          2m41s
      reviews-v1-7f99cc4496-gdxfn       2/2     Running   0          2m41s
      reviews-v2-7d79d5bd5d-8zzqd       2/2     Running   0          2m41s
      reviews-v3-7dbcdcbc56-m8dph       2/2     Running   0          2m41s
    ```
    Re-run the previous command and wait until all pods report READY 2/2 and STATUS Running before you go to the next step. This might take a few minutes depending on your platform.
  3. Verify everything is working correctly up to this point. Run this command to see if the app is running inside the cluster and serving HTML pages by checking for the page title in the response:
    ```bash
    $ kubectl exec "$(kubectl get pod -l app=ratings -o jsonpath='{.items[0].metadata.name}')" -c ratings -- curl -sS productpage:9080/productpage | grep -o "<title>.*</title>"
        <title>Simple Bookstore App</title>
    ```
    https://istio.io/latest/docs/setup/getting-started/
   
If you don’t have enough RAM allocated to the minikube virtual machine, the following errors could occur:
-  image pull failures
-  healthcheck timeout failures
-  kubectl failures on the host
-  general network instability of the virtual machine and the host
-  complete lock-up of the virtual machine
-  host NMI watchdog reboots
 
      One effective way to monitor memory usage in minikube is to ssh into the minikube virtual machine and from that prompt run the top command:
    ```
    $ minikube ssh

    $ top
    GiB Mem : 12.4/15.7
    ```
    This shows 12.4GiB used of an available 15.7 GiB RAM within the virtual machine. This data was generated with the VMWare Fusion hypervisor on a Macbook Pro 13” with 16GiB RAM running Istio 1.2 with bookinfo installed.

3. Label the default namespace to enable istio sidecar injection for the namespace
```
kubectl label namespace default istio-injection=enabled
```
## An added bonus from using the minikube tunnel command
[reference](https://istio.io/latest/docs/setup/platform-setup/minikube/)

(Optional, recommended) If you want minikube to provide a load balancer for use by Istio, you can use the minikube tunnel feature. Run this command in a different terminal, because the minikube tunnel feature will block your terminal (if os is windows , you need to ***Run as Administator***) to output diagnostic information about the network:
```
$ minikube -p lab tunnel
```

While running minikube tunnel, the istio-ingressgateway Service will now have an external IP which can be retrieved via kubectl:
```bash
$ kubectl get svc -n istio-system istio-ingressgateway
NAME                   TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                            AGE
istio-ingressgateway   LoadBalancer   10.100.136.45   10.100.136.45   15020:31711/TCP,80:31298/TCP....   7d22h

```
You can use minikube service.
```
$ minikube -p lab -n  istio-system service  istio-ingressgateway
|--------------|----------------------|-------------------|-----------------------------|
|  NAMESPACE   |         NAME         |    TARGET PORT    |             URL             |
|--------------|----------------------|-------------------|-----------------------------|
| istio-system | istio-ingressgateway | status-port/15020 | http://192.168.99.179:32759 |
|              |                      | http2/80          | http://192.168.99.179:30681 |
|              |                      | https/443         | http://192.168.99.179:30081 |
|              |                      | kiali/15029       | http://192.168.99.179:30503 |
|              |                      | prometheus/15030  | http://192.168.99.179:30002 |
|              |                      | grafana/15031     | http://192.168.99.179:32179 |
|              |                      | tracing/15032     | http://192.168.99.179:30719 |
|              |                      | tls/15443         | http://192.168.99.179:30935 |
|--------------|----------------------|-------------------|-----------------------------|
* Opening service istio-system/istio-ingressgateway in default browser...
* Opening service istio-system/istio-ingressgateway in default browser...
* Opening service istio-system/istio-ingressgateway in default browser...
* Opening service istio-system/istio-ingressgateway in default browser...
* Opening service istio-system/istio-ingressgateway in default browser...
* Opening service istio-system/istio-ingressgateway in default browser...
* Opening service istio-system/istio-ingressgateway in default browser...
* Opening service istio-system/istio-ingressgateway in default browser...

```


Sometimes minikube does not clean up the tunnel network properly. To force a proper cleanup:
```
$ minikube tunnel --cleanup
```
### workaround by other methods
#### Install keepalived loadbalancer 
helm v2 to install under k8s1.16+
```
$  minikube -p sample start
$  kubectl label node sample [default:minikube] proxy=true
$  kubectl create clusterrolebinding \
   keepalived-cluster-role-binding \
   --clusterrole=cluster-admin --serviceaccount=keepalived:default
$  kubectl create namespace keepalived
$  git clone https://github.com/robert0714/keepalived.git 
$  cd keepalived && git  checkout k8s-1.16  && cd ..
$  helm install keepalived --name keepalived \
   --namespace keepalived \
   --set keepalivedCloudProvider.serviceIPRange="192.168.99.150/29" \
   --set nameOverride="lb"
```
helm v3
```
 helm install keepalived  keepalived \
   --namespace keepalived \
   --set keepalivedCloudProvider.serviceIPRange="192.168.99.150/29" \
   --set nameOverride="lb"
```
to make sure :
```bash
$ kubectl get svc -n istio-system istio-ingressgateway
NAME                   TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                                                                                                                      AGE
istio-ingressgateway   LoadBalancer   10.111.84.81   192.168.99.145   15020:32759/TCP,80:30681/TCP,443:30081/TCP,15029:30503/TCP,15030:30002/TCP,15031:32179/TCP,15032:30719/TCP,15443:30935/TCP   9m28s
```
#### Mappins the DNS name to the external Ip
Config minikube.me to be resolved to the IP address of the Istio Ingress Gateway as follows:
1. Get the IP address exposed by the keepalived loadbalancer for the Istio Ingress Gateway and save it in an environment variable named INGRESS_HOST:
```bash
INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
```
2. Update /etc/hosts so that minikube.me points to the Istio Ingress Gateway:
```
echo "$INGRESS_HOST minikube.me" | sudo tee -a /etc/hosts
```
If os is windows ,the file is C:\Windows\System32\drivers\etc\hosts. use administrative Powershell with the following command:
```
Add-Content -Path $env:windir\System32\drivers\etc\hosts -Value "`n$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')`tminikube.me" -Force
```

3. Remove the line in /etc/hosts where minikube.me that points to the IP address of the Minikube instance (minikube ip). Verify that /etc/hosts only contains one line that translates minikube.me and that it points to the IP address of the Istio Ingress Gateway.

### Verify that Kiali, Jaeger, and Grafana
Verify that Kiali, Jaeger, and Grafana can be reached through the tunnel with the following commands:
```bash
curl -o /dev/null -s -L -w "%{http_code}" http://kiali.istio-system.svc.cluster.local:20001/kiali/
curl -o /dev/null -s -L -w "%{http_code}" http://grafana.istio-system.svc.cluster.local:3000
curl -o /dev/null -s -L -w "%{http_code}" http://jaeger-query.istio-system.svc.cluster.local:16686
```
